<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <title>Albert Gordo</title>

  <link rel="stylesheet" href="stylesheets/styles.css">
  <link rel="stylesheet" href="stylesheets/pygment_trac.css">
  <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
     <header>
      <img src="albertgordo.png" alt="Albert Gordo" style="width:210px;">
      <br>
      <br>
      <h1>Albert Gordo</h1>
      <p><strong>Research Scientist</strong><br>
        <strong>Facebook</strong><br>
        <p> <a href="https://scholar.google.ca/citations?user=UgK1my4AAAAJ&hl=en">Google Scholar profile</a><br>
 	  <a href="https://www.linkedin.com/in/albert-gordo/">LinkedIn profile</a><br>
          <a href="http://dblp.uni-trier.de/pers/hd/g/Gordo:Albert">DBLP profile</a><br>
          <a href="http://patents.justia.com/search?q=albert+gordo">Patents</a><br>
        </p>

      </header>

      <section>
        <a name="about"></a>
        <h2>About me</h2>
        <p>
          I received my Ph.D. from the Computer Vision Center in the Universitat Autonoma de Barcelona, Spain, in collaboration with the Computer Vision group at XRCE, supervised by <a href="https://scholar.google.fr/citations?user=ChmX8ogAAAAJ&hl=en">Ernest Valveny</a> and <a href="http://www.xrce.xerox.com/About-XRCE/People/Florent-Perronnin">Florent Perronnin</a>. After that I was a postdoc at the LEAR group in INRIA Grenoble, working on large-scale object detection with <a href="http://thoth.inrialpes.fr/~schmid/">Cordelia Schmid</a>. From 2014 to 2017 I was a research scientist in the <a href="http://www.xrce.xerox.com/Our-Research/Computer-Vision">Computer Vision group</a> at XRCE. Since June 2017 I am a research scientist at Facebook.
        </p>
        <a name="news"></a>
        <h2>Recent news</h2>
        <ul>
	  <li>One paper accepted at CVPR 2022: <b>Generating High Fidelity Data from Low-density Regions using Diffusion Models</b><br>
          [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Sehwag_Generating_High_Fidelity_Data_From_Low-Density_Regions_Using_Diffusion_Models_CVPR_2022_paper.pdf">PDF</a>]</li>
	  <li>One article accepted at IEEE Transactions on Biometrics, Behavior,and Identity Science: <b>Towards Measuring Fairness in AI: the Casual Conversations Dataset</b><br>
          [<a href=https://arxiv.org/pdf/2104.02821.pdf">PDF</a>]</li>
	  <li>One paper accepted at AAAI 2021: <b>Using Hindsight to Anchor Past Knowledge in Continual Learning</b><br>
          [<a href="https://arxiv.org/pdf/2002.08165.pdf">PDF</a>]</li>
	  <li>One paper accepted at ECCV 2020: <b>Attention-Based Query Expansion Learning</b><br>
          [<a href="https://research.fb.com/wp-content/uploads/2020/08/Attention-Based-Query-Expansion-Learning.pdf">PDF</a>]</li>
	  <li>One paper accepted at ICLR 2020: <b>Decoupling Representation and Classifier for Long-Tailed Recognition</b><br>
          [<a href="https://openreview.net/pdf?id=r1gRTCVFvB">PDF</a>]</li>
	  <li>One paper accepted at KDD 2018 (Oral): <b>Rosetta: Large scale system for text detection and recognition in images</b><br>
		  [<a href="https://research.fb.com/wp-content/uploads/2018/10/Rosetta-Large-scale-system-for-text-detection-and-recognition-in-images.pdf">PDF</a>, <a href="https://www.youtube.com/watch?v=yl3P2tYewVg">Promo video</a>, <a href="https://code.fb.com/ai-research/rosetta-understanding-text-in-images-and-videos-with-machine-learning">Blog post</a>]<br>
		  This work has received some attention from the press.
      Amongst others, <a href="https://www.cnet.com/news/facebooks-new-rosetta-ai-system-helps-detect-hate-speech/">CNET</a>,
                      <a href="https://mashable.com/article/facebook-rosetta-ai-for-reading-memes/#ewc19uqlgZqn"> Mashable</a>,
                      <a href="https://www.zdnet.com/article/facebook-pumps-up-character-recognition-to-mine-memes/">ZDNet</a>,
                      <a href="https://techcrunch.com/2018/09/11/facebooks-rosetta-system-helps-the-company-understand-memes/">TechCrunch</a>,
                      <a href="https://www.engadget.com/2018/09/11/facebook-rosetta-ai-translation/">Engadget</a>,
                      <a href="https://www.theverge.com/2018/9/11/17846512/facebook-rosetta-meme-machine-learning-text-recognition-hate-speech">The Verge</a>, or
                      <a href="https://www.wired.com/story/facebook-rosetta-ai-memes/">WIRED</a>.

    </li>

          <li>Since June 2017 I am a <b>research scientist</b> at <b>Facebook</b></li>
          <li>Article accepted at IJCV: <b>End-to-end Learning of Deep Visual Representations for Image Retrieval</b><br>
          [<a href="https://arxiv.org/abs/1610.07940">PDF</a>, <a href="http://www.xrce.xerox.com/Our-Research/Computer-Vision/Learning-Visual-Representations/Deep-Image-Retrieval">Project</a>]</li>
          <li>Invited talks about our recent papers on image retrieval:
            <ul>
              <li>École de Technologie Supérieure, Montréal, May 2017</li>
              <li>Cornell University AI seminar, February 2017</li>
              <li>Cornell Tech, NY, February 2017</li>
              <li>THOTH group, INRIA, September 2016</li>
              <li>GTC Europe, September 2016</li>
            </ul>
          </li>
          <li>One paper accepted at CVPR 2017: <b>Beyond Instance-level Image Retrieval: Leveraging Captions to Learn a Global Visual Representation for Semantic Retrieval</b><br>
        [<a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Gordo_Beyond_Instance-Level_Image_CVPR_2017_paper.pdf">PDF</a>]</li>
        <li>One paper accepted at ECCV 2016: <b>Deep Image Retrieval: Learning global representations for image search</b><br>
        [<a href="https://arxiv.org/abs/1604.01325">PDF</a>, <a href="http://www.xrce.xerox.com/Our-Research/Computer-Vision/Learning-Visual-Representations/Deep-Image-Retrieval">Project</a>]</li>
        <li>One paper accepted at ICCV 2015: <b>LEWIS: Latent Embeddings for Word Images and their Semantics</b><br>
        [<a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Gordo_LEWIS_Latent_Embeddings_ICCV_2015_paper.pdf">PDF</a>]</li>
        <li>Outstanding reviewer award at <a href="http://www.pamitc.org/cvpr15/awards.php">CVPR 2015</a></li>
        <li>Winning team (with some colleagues from the Computer Vision Center in Barcelona) of the <a href="http://www.icfhr2014.org/wp-content/uploads/2015/02/ICFHR2014-H-KWS.pdf">Handwritten Keyword Spotting Competition</a>, track I, held at ICFHR 2014</li>
        <!--
        <li>Invited talk at the Computer Vision Center in Barcelona, Spain. Deep fishing: Extracting Gradient Features from Deep Nets / LEWIS: Latent embeddings for word images and their semantics. Video available here </li>
        <li>One paper accepted at CVPR 2015! Supervised Mid-Level Features for Word Image Representation</li>
        <li>Invited talk at INRIA's µ-Workshop on Computer Vision: Towards Text Understanding: Word Image Representation, Matching and Recognition. Slides and video available</li>
        -->
      </ul>
	<p></p>
	<p></p>
	<p></p>
	<p></p>

      <p><small>Theme adapted from <a href="https://github.com/orderedlist/minimal">orderedlist/minimal</a>.</small></p>
    </section>
    <footer>
    </footer>
  </div>
  <script src="javascripts/scale.fix.js"></script>
</body>
</html>
